<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>8 Corpora</title>
    <meta charset="utf-8" />
    <meta name="author" content="Métodos empíricos 2" />
    <link href="slides_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="slides_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# 8 Corpora
]
.author[
### Métodos empíricos 2
]
.date[
### 31/05/2022
]

---




# Hoy

.large[
* Las leyes de Zipf

* Corpora y pre-procesamiento

* Aplicaciones

* Word embeddings y más allá

]

---

class: inverse, center

# Las leyes de Zipf


.footnote[
***

G.K. Zipf (1935) *The psycho-biology of language*⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀

G.K. Zipf (1949) *Human behavior and the principle of least effort*

]

---

### 1. Zipf's (Rank-Frequency) Law

### 2. Zipf's Law of Abbreviation

### 3. Zipf's Meaning-Frequency Law

---

### Rank-Frequency Law: La distribución rango-frecuencia de palabras es inversa

&lt;img src="Zipf_30wiki_en_labels.png" width="90%" style="display: block; margin: auto;" /&gt;

---

### Law of Abbreviation: Formas frequentes tienden a ser más cortas 


&lt;img src="en-zipf.jpg" width="80%" style="display: block; margin: auto;" /&gt;

---

### Meaning-frequency Law: Formas frequentes tienden a tener más significados

&lt;img src="slides_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

class: inverse, center

# Corpora y pre-procesamiento

---

# Corpora

* Por definición: Cualquier colección de datos

* Por uso convencional: Colección de datos no estructurados, muchas veces de [gran]() tamaño


.footnote[
***

Lo que significa [gran]() varía en función a la naturaleza de los datos, y de cuándo son / es el análisis.]

---

# Associated Press Corpus 

Colección de 2246 artículos de noticias, la mayoría de alrededor de 1988

--

&lt;img src="ap-story.png" width="1931" /&gt;


---

# Tokenización

--

Segmentar y transformar tu corpus para que represente las unidades de tu análisis.

Por ejemplo, palabras, morfémas, o caracteres.

---

# Tokenización a nivel de palabras


```r
library(stringr)

first_par &lt;- 'MEXICO CITY (AP) — The Mexican government said Tuesday that COVID-19 has passed from a pandemic to an endemic stage in Mexico, meaning authorities will treat it as a seasonally recurring disease.'

tokenized_first_par &lt;- str_split(first_par, pattern = " ")[[1]]
tokenized_first_par
```

```
##  [1] "MEXICO"      "CITY"        "(AP)"        "—"           "The"        
##  [6] "Mexican"     "government"  "said"        "Tuesday"     "that"       
## [11] "COVID-19"    "has"         "passed"      "from"        "a"          
## [16] "pandemic"    "to"          "an"          "endemic"     "stage"      
## [21] "in"          "Mexico,"     "meaning"     "authorities" "will"       
## [26] "treat"       "it"          "as"          "a"           "seasonally" 
## [31] "recurring"   "disease."
```

---

# Procesos de normalización de token(e)s

--

## Casing

Convertir todo el texto a minúscula (o mayúscula)

--

## Stemming

Quitar material morfológico, quedandose sólamente con las raíces

--


## Lematización

Cambiar palabras por sus respectivos lemas.

---

# Casing


```r
tolower(tokenized_first_par)
```

```
##  [1] "mexico"      "city"        "(ap)"        "—"           "the"        
##  [6] "mexican"     "government"  "said"        "tuesday"     "that"       
## [11] "covid-19"    "has"         "passed"      "from"        "a"          
## [16] "pandemic"    "to"          "an"          "endemic"     "stage"      
## [21] "in"          "mexico,"     "meaning"     "authorities" "will"       
## [26] "treat"       "it"          "as"          "a"           "seasonally" 
## [31] "recurring"   "disease."
```

---

# Stemming &amp; lemmatization

* cat, cats, cat's, cats'; ...

* to be; am; are; were; ...


---

# AP tokenizada



```r
library(tidytext)

data("AssociatedPress", package = "topicmodels")
tidy(AssociatedPress)
```




```
## # A tibble: 6 × 3
##   document term      count
##      &lt;int&gt; &lt;chr&gt;     &lt;dbl&gt;
## 1        1 adding        1
## 2        1 adult         2
## 3        1 ago           1
## 4        1 alcohol       1
## 5        1 allegedly     1
## 6        1 allen         1
```

---

# AP y Zipf?


```
## # A tibble: 6 × 6
##   term    count length  rank log.count log.rank
##   &lt;chr&gt;   &lt;dbl&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 i        2073      1     1      7.64    0    
## 2 new      2014      3     2      7.61    0.693
## 3 percent  1949      7     3      7.58    1.10 
## 4 people   1662      6     4      7.42    1.39 
## 5 year     1576      4     5      7.36    1.61 
## 6 two      1570      3     6      7.36    1.79
```

---

# AP y Zipf I

&lt;img src="slides_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;

---

# AP y Zipf II

&lt;img src="slides_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---

# Jane Austen


```
## # A tibble: 73,422 × 4
##    text                    book                 line chapter
##    &lt;chr&gt;                   &lt;fct&gt;               &lt;int&gt;   &lt;int&gt;
##  1 "SENSE AND SENSIBILITY" Sense &amp; Sensibility     1       0
##  2 ""                      Sense &amp; Sensibility     2       0
##  3 "by Jane Austen"        Sense &amp; Sensibility     3       0
##  4 ""                      Sense &amp; Sensibility     4       0
##  5 "(1811)"                Sense &amp; Sensibility     5       0
##  6 ""                      Sense &amp; Sensibility     6       0
##  7 ""                      Sense &amp; Sensibility     7       0
##  8 ""                      Sense &amp; Sensibility     8       0
##  9 ""                      Sense &amp; Sensibility     9       0
## 10 "CHAPTER 1"             Sense &amp; Sensibility    10       1
## # … with 73,412 more rows
```

---

# Jane Austen tokenizada y normalizada


```
## # A tibble: 725,055 × 4
##    book                 line chapter word       
##    &lt;fct&gt;               &lt;int&gt;   &lt;int&gt; &lt;chr&gt;      
##  1 Sense &amp; Sensibility     1       0 sense      
##  2 Sense &amp; Sensibility     1       0 and        
##  3 Sense &amp; Sensibility     1       0 sensibility
##  4 Sense &amp; Sensibility     3       0 by         
##  5 Sense &amp; Sensibility     3       0 jane       
##  6 Sense &amp; Sensibility     3       0 austen     
##  7 Sense &amp; Sensibility     5       0 1811       
##  8 Sense &amp; Sensibility    10       1 chapter    
##  9 Sense &amp; Sensibility    10       1 1          
## 10 Sense &amp; Sensibility    13       1 the        
## # … with 725,045 more rows
```


---

# Jane Austen y Zipf?


```
## # A tibble: 6 × 6
##   word  count length log.count  rank log.rank
##   &lt;chr&gt; &lt;int&gt;  &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;
## 1 the   26351      3     10.2      1    0    
## 2 to    24044      2     10.1      2    0.693
## 3 and   22515      3     10.0      3    1.10 
## 4 of    21178      2      9.96     4    1.39 
## 5 a     13408      1      9.50     5    1.61 
## 6 her   13055      3      9.48     6    1.79
```

---


# Jane Austen y Zipf I

![](slides_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;

---

# Jane Austen y Zipf II

![](slides_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---

# Y la otra ley de Zipf?


---

# Discusión

* Todo tipo de texto sigue las Leyes de Zipf?

* Toda lengua sigue las Leyes de Zipf?


---

class: inverse

# Aplicaciones 

---

# Investigación

* Indispensable para descubrir o (des)confirmar regularidades en una, o varias lenguas

* Mayor volúmen de datos `\(\Rightarrow\)` mayor sensibilidad para encontrar efectos menores (pero también más peligro de descubrir patrones falsos)

  * [https://www.tylervigen.com/spurious-correlations](https://www.tylervigen.com/spurious-correlations)

* Gran potencial --aún por explorar-- para tipología y lenguas menos descritas

---


# Industria

* (Pre-)procesamiento de grandes volúmenes de datos lingüísticos

* Indispensable para descubrir o (des)confirmar regularidades a nivel de individuos, grupos y comunidades

* Enorme mercado que todavía se está abriendo

---

class: inverse

# Word embeddings y más allá


---

# Predicción como base para conocimiento lingüístico

### Les ⬛⬛⬛....⬛⬛⬛

--

### Les tasques ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació i ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació i ampliació ⬛⬛⬛....⬛⬛⬛


---

# Predicción como base para conocimiento lingüístico

### Les tasques de remodelació i ampliació de ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació i ampliació de l' ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació i ampliació de l'estadi ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació i ampliació de l'estadi començaran ⬛⬛⬛....⬛⬛⬛

---

# Predicción como base para conocimiento lingüístico


### Les tasques de remodelació i ampliació de l'estadi començaran al ⬛⬛⬛....⬛⬛⬛

--

### Les tasques de remodelació i ampliació de l'estadi començaran al juny ⬛⬛⬛....⬛⬛⬛


---

# Predicción como base para conocimiento lingüístico

Entrenar modelos con muchos parámetros a predecir información lingüística en grandes volúmenes de datos 

`\(\Large \Rightarrow\)`  aprendizaje de conocimiento lingüístico latente (hasta cierto grado)

--

&lt;br&gt;

* Syntáxis ✔

* Morfología ✔

* Semántica ✔✘

* Pragmática ✘

---

# Word embeddings

&lt;img src="ds-boleda.png" width="90%" style="display: block; margin: auto;" /&gt;

---

# Word embeddings

&lt;img src="ds-semantic-change.png" width="90%" style="display: block; margin: auto;" /&gt;

---


# Language models

[https://transformer.huggingface.co/doc/distil-gpt2](https://transformer.huggingface.co/doc/distil-gpt2)


---

# Paquetes

* python: spaCy, (py)torch

* R: tidytext, stringr

---

# Siguentes avances

* Modelos multi-modales

* Calidad de datos vs. tamaño de modelo

* Límites de aprendizaje a base de texto

* Black box NLP &amp; lenguaje emergente


---


class: inverse

# Próxima sesión

* No hay entrega

***

* **Visualización**

***

* Informe final: 28/06
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "github"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
